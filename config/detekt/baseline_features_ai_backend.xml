<?xml version="1.0" ?>
<SmellBaseline>
  <ManuallySuppressedIssues/>
  <CurrentIssues>
    <ID>ArgumentListWrapping:EmbeddingService.kt$EmbeddingService$("OpenAI embeddings generated: count=${results.size}, dimensions=${results.firstOrNull()?.dimensions}")</ID>
    <ID>ArgumentListWrapping:RAGService.kt$RAGService$("Query embedding generated: dimensions=${queryEmbedding.dimensions}, model=${queryEmbedding.model}")</ID>
    <ID>CyclomaticComplexMethod:ChatAgent.kt$ChatAgent$suspend fun chat( tenantId: TenantId, question: String, documentId: DocumentId? = null, conversationHistory: List&lt;ConversationMessage&gt;? = null, topK: Int = DEFAULT_TOP_K, minSimilarity: Float = DEFAULT_MIN_SIMILARITY ): ChatResponse</ID>
    <ID>CyclomaticComplexMethod:DocumentAIResult.kt$fun DocumentAIResult.meetsMinimalThreshold(): Boolean</ID>
    <ID>CyclomaticComplexMethod:DocumentAIResult.kt$private fun InvoiceProvenance.toFieldConfidences(): Map&lt;String, Double&gt;</ID>
    <ID>ImplicitDefaultLocale:RAGService.kt$RAGService$String.format("%.0f%%", chunk.similarityScore * 100)</ID>
    <ID>ImportOrdering:InboundInvoiceExtractionAgent.kt$import tech.dokus.ai.models.InboundInvoiceProvenance import tech.dokus.ai.models.ExtractedInvoiceData import tech.dokus.ai.models.FieldProvenance import ai.koog.agents.core.agent.AIAgent import ai.koog.agents.core.agent.singleRunStrategy import ai.koog.agents.core.tools.ToolRegistry import ai.koog.prompt.executor.model.PromptExecutor import ai.koog.prompt.llm.LLModel import kotlinx.serialization.json.Json import tech.dokus.foundation.backend.utils.loggerFor</ID>
    <ID>ImportOrdering:CategorySuggestionAgent.kt$import tech.dokus.ai.models.CategorySuggestion import ai.koog.agents.core.agent.AIAgent import ai.koog.agents.core.agent.singleRunStrategy import ai.koog.agents.core.tools.ToolRegistry import ai.koog.prompt.executor.model.PromptExecutor import ai.koog.prompt.llm.LLModel import kotlinx.serialization.json.Json import tech.dokus.foundation.backend.utils.loggerFor</ID>
    <ID>ImportOrdering:ChatAgent.kt$import tech.dokus.ai.services.RAGService import tech.dokus.domain.ids.DocumentId import tech.dokus.domain.ids.TenantId import tech.dokus.domain.repository.RetrievedChunk import ai.koog.agents.core.agent.AIAgent import ai.koog.agents.core.agent.singleRunStrategy import ai.koog.agents.core.tools.ToolRegistry import ai.koog.prompt.executor.model.PromptExecutor import ai.koog.prompt.llm.LLModel import kotlinx.serialization.Serializable import kotlinx.serialization.json.Json import org.slf4j.LoggerFactory</ID>
    <ID>ImportOrdering:ChunkingService.kt$import tech.dokus.domain.model.ChunkMetadata import tech.dokus.domain.model.ChunkProvenance import tech.dokus.domain.model.ChunkingConfig import tech.dokus.domain.model.TextOffsets import org.slf4j.LoggerFactory</ID>
    <ID>ImportOrdering:DocumentClassificationAgent.kt$import tech.dokus.ai.models.ClassifiedDocumentType import tech.dokus.ai.models.DocumentClassification import ai.koog.agents.core.agent.AIAgent import ai.koog.agents.core.agent.singleRunStrategy import ai.koog.agents.core.tools.ToolRegistry import ai.koog.prompt.executor.model.PromptExecutor import ai.koog.prompt.llm.LLModel import kotlinx.serialization.json.Json import tech.dokus.foundation.backend.utils.loggerFor</ID>
    <ID>ImportOrdering:EmbeddingService.kt$import tech.dokus.domain.model.ai.AiProvider import tech.dokus.foundation.backend.config.AIConfig import tech.dokus.foundation.backend.utils.loggerFor import io.ktor.client.HttpClient import io.ktor.client.call.body import io.ktor.client.request.header import io.ktor.client.request.post import io.ktor.client.request.setBody import io.ktor.http.ContentType import io.ktor.http.contentType import kotlinx.serialization.SerialName import kotlinx.serialization.Serializable import kotlinx.serialization.json.Json</ID>
    <ID>ImportOrdering:InvoiceExtractionAgent.kt$import tech.dokus.ai.models.ExtractedInvoiceData import tech.dokus.ai.models.FieldProvenance import tech.dokus.ai.models.InvoiceProvenance import ai.koog.agents.core.agent.AIAgent import ai.koog.agents.core.agent.singleRunStrategy import ai.koog.agents.core.tools.ToolRegistry import ai.koog.prompt.executor.model.PromptExecutor import ai.koog.prompt.llm.LLModel import kotlinx.serialization.json.Json import tech.dokus.foundation.backend.utils.loggerFor</ID>
    <ID>ImportOrdering:RAGService.kt$import tech.dokus.domain.ids.DocumentId import tech.dokus.domain.ids.TenantId import tech.dokus.domain.model.ChunkRetrievalRequest import tech.dokus.domain.model.ChunkRetrievalResponse import tech.dokus.domain.model.DocumentChunkId import tech.dokus.domain.model.DocumentChunkSummary import tech.dokus.domain.repository.ChunkRepository import tech.dokus.domain.repository.DocumentStatusChecker import tech.dokus.domain.repository.IngestionStatusChecker import tech.dokus.domain.repository.RetrievedChunk import org.slf4j.LoggerFactory import kotlin.uuid.ExperimentalUuidApi</ID>
    <ID>LongMethod:ChatAgent.kt$ChatAgent$suspend fun chat( tenantId: TenantId, question: String, documentId: DocumentId? = null, conversationHistory: List&lt;ConversationMessage&gt;? = null, topK: Int = DEFAULT_TOP_K, minSimilarity: Float = DEFAULT_MIN_SIMILARITY ): ChatResponse</ID>
    <ID>LongMethod:ChunkingService.kt$ChunkingService$fun chunkSemantic( text: String, config: ChunkingConfig = DEFAULT_CONFIG ): ChunkingResult</ID>
    <ID>LongParameterList:ChatAgent.kt$ChatAgent$( tenantId: TenantId, question: String, documentId: DocumentId? = null, conversationHistory: List&lt;ConversationMessage&gt;? = null, topK: Int = DEFAULT_TOP_K, minSimilarity: Float = DEFAULT_MIN_SIMILARITY )</ID>
    <ID>LoopWithTooManyJumpStatements:ChunkingService.kt$ChunkingService$while</ID>
    <ID>MagicNumber:AIProviderFactory.kt$AIProviderFactory$1024</ID>
    <ID>MagicNumber:AIProviderFactory.kt$AIProviderFactory$1536</ID>
    <ID>MagicNumber:AIProviderFactory.kt$AIProviderFactory$3072</ID>
    <ID>MagicNumber:AIProviderFactory.kt$AIProviderFactory$32768L</ID>
    <ID>MagicNumber:AIProviderFactory.kt$AIProviderFactory$384</ID>
    <ID>MagicNumber:AIProviderFactory.kt$AIProviderFactory$4096L</ID>
    <ID>MagicNumber:AIProviderFactory.kt$AIProviderFactory$768</ID>
    <ID>MagicNumber:AIProviderFactory.kt$AIProviderFactory$8192L</ID>
    <ID>MagicNumber:AIService.kt$AIService$0.5</ID>
    <ID>MagicNumber:InboundInvoiceExtractionAgent.kt$InboundInvoiceExtractionAgent$50</ID>
    <ID>MagicNumber:InboundInvoiceExtractionAgent.kt$InboundInvoiceExtractionAgent$500</ID>
    <ID>MagicNumber:CategorySuggestionAgent.kt$CategorySuggestionAgent$500</ID>
    <ID>MagicNumber:ChatAgent.kt$ChatAgent$0.2f</ID>
    <ID>MagicNumber:ChatAgent.kt$ChatAgent$0.6f</ID>
    <ID>MagicNumber:ChatAgent.kt$ChatAgent$100</ID>
    <ID>MagicNumber:ChatAgent.kt$ChatAgent$200</ID>
    <ID>MagicNumber:ChatAgent.kt$ChatAgent$5</ID>
    <ID>MagicNumber:ChunkingService.kt$ChunkingService$100</ID>
    <ID>MagicNumber:ChunkingService.kt$ChunkingService$50</ID>
    <ID>MagicNumber:ChunkingService.kt$ChunkingService.Chunk$4</ID>
    <ID>MagicNumber:EmbeddingService.kt$EmbeddingService$200</ID>
    <ID>MagicNumber:EmbeddingService.kt$EmbeddingService$299</ID>
    <ID>MagicNumber:InvoiceExtractionAgent.kt$InvoiceExtractionAgent$50</ID>
    <ID>MagicNumber:InvoiceExtractionAgent.kt$InvoiceExtractionAgent$500</ID>
    <ID>MagicNumber:RAGService.kt$RAGService$100</ID>
    <ID>MagicNumber:RAGService.kt$RAGService$4</ID>
    <ID>MagicNumber:ReceiptExtractionAgent.kt$ReceiptExtractionAgent$500</ID>
    <ID>MaxLineLength:ChatAgent.kt$ChatAgent$DocumentState.NOT_INDEXED -&gt; "Document has not been indexed for chat. Please ensure the document has been processed."</ID>
    <ID>MaxLineLength:ChunkingService.kt$ChunkingService$if</ID>
    <ID>MaxLineLength:ChunkingService.kt$ChunkingService$text.length &lt; 100 &amp;&amp; text.all { it.isUpperCase() || it.isWhitespace() || it.isDigit() || it in ".-:/" } -&gt; "header"</ID>
    <ID>MaxLineLength:EmbeddingService.kt$EmbeddingService$logger.debug("OpenAI embeddings generated: count=${results.size}, dimensions=${results.firstOrNull()?.dimensions}")</ID>
    <ID>MaxLineLength:RAGService.kt$RAGService$logger.debug("Query embedding generated: dimensions=${queryEmbedding.dimensions}, model=${queryEmbedding.model}")</ID>
    <ID>MaximumLineLength:ChatAgent.kt$ChatAgent$ </ID>
    <ID>MaximumLineLength:ChunkingService.kt$ChunkingService$ </ID>
    <ID>MaximumLineLength:EmbeddingService.kt$EmbeddingService$ </ID>
    <ID>MaximumLineLength:RAGService.kt$RAGService$ </ID>
    <ID>NestedBlockDepth:ChatAgent.kt$ChatAgent$suspend fun chat( tenantId: TenantId, question: String, documentId: DocumentId? = null, conversationHistory: List&lt;ConversationMessage&gt;? = null, topK: Int = DEFAULT_TOP_K, minSimilarity: Float = DEFAULT_MIN_SIMILARITY ): ChatResponse</ID>
    <ID>NoConsecutiveBlankLines:RAGService.kt$RAGService$ </ID>
    <ID>NoMultipleSpaces:ExtractedInvoiceData.kt$InboundInvoiceLineItem$ </ID>
    <ID>NoMultipleSpaces:ExtractedInvoiceData.kt$ExtractedInvoiceData$ </ID>
    <ID>NoMultipleSpaces:ExtractedInvoiceData.kt$ExtractedInvoiceData$ </ID>
    <ID>NoMultipleSpaces:ExtractedInvoiceData.kt$InvoiceLineItem$ </ID>
    <ID>NoMultipleSpaces:ExtractedInvoiceData.kt$VatBreakdown$ </ID>
    <ID>NoMultipleSpaces:ExtractedReceiptData.kt$ExtractedReceiptData$ </ID>
    <ID>ReturnCount:InboundInvoiceExtractionAgent.kt$InboundInvoiceExtractionAgent$private fun enhanceFieldProvenance( provenance: FieldProvenance?, ocrText: String ): FieldProvenance?</ID>
    <ID>ReturnCount:InvoiceExtractionAgent.kt$InvoiceExtractionAgent$private fun enhanceFieldProvenance( provenance: FieldProvenance?, ocrText: String ): FieldProvenance?</ID>
    <ID>SpacingBetweenDeclarationsWithComments:ChatAgent.kt$ChatAgent.DocumentState.NOT_CONFIRMED$/** Document has not been confirmed by the user - chat not allowed */</ID>
    <ID>SpacingBetweenDeclarationsWithComments:ChatAgent.kt$ChatAgent.DocumentState.NOT_INDEXED$/** Document is not indexed for chat */</ID>
    <ID>SpacingBetweenDeclarationsWithComments:ChatAgent.kt$ChatAgent.DocumentState.PROCESSING$/** Document is still being processed */</ID>
    <ID>SpacingBetweenDeclarationsWithComments:ChunkingService.kt$ChunkingService.ChunkingStrategy.FIXED$/** Fixed-size chunks with overlap */</ID>
    <ID>SwallowedException:DocumentAIResult.kt$e: Exception</ID>
    <ID>ThrowsCount:EmbeddingService.kt$EmbeddingService$private suspend fun generateOllamaEmbedding(text: String, model: String): EmbeddingResult</ID>
    <ID>ThrowsCount:EmbeddingService.kt$EmbeddingService$private suspend fun generateOpenAIEmbeddingsBatch( texts: List&lt;String&gt;, model: String ): List&lt;EmbeddingResult&gt;</ID>
    <ID>TooGenericExceptionCaught:InboundInvoiceExtractionAgent.kt$InboundInvoiceExtractionAgent$e: Exception</ID>
    <ID>TooGenericExceptionCaught:CategorySuggestionAgent.kt$CategorySuggestionAgent$e: Exception</ID>
    <ID>TooGenericExceptionCaught:ChatAgent.kt$ChatAgent$e: Exception</ID>
    <ID>TooGenericExceptionCaught:DocumentAIResult.kt$e: Exception</ID>
    <ID>TooGenericExceptionCaught:DocumentClassificationAgent.kt$DocumentClassificationAgent$e: Exception</ID>
    <ID>TooGenericExceptionCaught:EmbeddingService.kt$EmbeddingService$e: Exception</ID>
    <ID>TooGenericExceptionCaught:InvoiceExtractionAgent.kt$InvoiceExtractionAgent$e: Exception</ID>
    <ID>TooGenericExceptionCaught:RAGService.kt$RAGService$e: Exception</ID>
    <ID>TooGenericExceptionCaught:ReceiptExtractionAgent.kt$ReceiptExtractionAgent$e: Exception</ID>
    <ID>TooManyFunctions:DocumentAIResult.kt$tech.dokus.ai.models.DocumentAIResult.kt</ID>
    <ID>UnusedParameter:ChunkingService.kt$ChunkingService$config: ChunkingConfig</ID>
    <ID>UnusedParameter:DocumentAIResult.kt$currencyCode: String?</ID>
    <ID>UnusedPrivateProperty:ChatAgent.kt$ChatAgent$private val json = Json { ignoreUnknownKeys = true isLenient = true }</ID>
    <ID>UnusedPrivateProperty:ChunkingService.kt$ChunkingService.Companion$private val WHITESPACE_PATTERN = Regex("\\s+")</ID>
    <ID>Wrapping:ChunkingService.kt$ChunkingService$(</ID>
  </CurrentIssues>
</SmellBaseline>
